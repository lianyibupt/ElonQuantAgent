"""
SQLiteæ•°æ®åº“ç®¡ç†æ¨¡å—
ç”¨äºå­˜å‚¨æŸ¥è¯¢è®°å½•ã€APIç¼“å­˜å’ŒæŠ€æœ¯åˆ†æç»“æœ
"""

import sqlite3
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union
from pathlib import Path
import os


class DatabaseManager:
    """SQLiteæ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„trading_data.db
        """
        if db_path is None:
            # é»˜è®¤æ•°æ®åº“è·¯å¾„ï¼šé¡¹ç›®æ ¹ç›®å½•ä¸‹
            project_root = Path(__file__).parent
            db_path = project_root / "trading_data.db"
        
        self.db_path = str(db_path)
        self._ensure_database_exists()
        self._init_tables()
    
    def _ensure_database_exists(self):
        """ç¡®ä¿æ•°æ®åº“æ–‡ä»¶å­˜åœ¨"""
        db_dir = os.path.dirname(self.db_path)
        if db_dir and not os.path.exists(db_dir):
            os.makedirs(db_dir, exist_ok=True)
    
    def get_connection(self) -> sqlite3.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row  # å…è®¸é€šè¿‡åˆ—åè®¿é—®
        return conn
    
    def _init_tables(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        with self.get_connection() as conn:
            # æŸ¥è¯¢è®°å½•è¡¨
            conn.execute("""
                CREATE TABLE IF NOT EXISTS query_records (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    tickers TEXT NOT NULL,
                    start_date DATE,
                    end_date DATE,
                    analysis_params TEXT,  -- JSONæ ¼å¼å­˜å‚¨åˆ†æå‚æ•°
                    user_ip TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # æŠ€æœ¯åˆ†æç»“æœè¡¨
            conn.execute("""
                CREATE TABLE IF NOT EXISTS analysis_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    query_record_id INTEGER,
                    ticker TEXT NOT NULL,
                    current_price REAL,
                    signal TEXT,  -- çœ‹æ¶¨/çœ‹è·Œ/ä¸­æ€§
                    confidence INTEGER,
                    reason TEXT,
                    macd_signal TEXT,
                    rsi_signal TEXT,
                    bollinger_signal TEXT,
                    volume_signal TEXT,
                    recommendation TEXT,
                    recommendation_action TEXT,
                    data_days INTEGER,
                    pe_ratio REAL,
                    pb_ratio REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (query_record_id) REFERENCES query_records (id)
                )
            """)
            
            # APIç¼“å­˜è¡¨ - ä»·æ ¼æ•°æ®
            conn.execute("""
                CREATE TABLE IF NOT EXISTS price_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    date DATE NOT NULL,
                    open_price REAL,
                    high_price REAL,
                    low_price REAL,
                    close_price REAL,
                    volume INTEGER,
                    api_source TEXT DEFAULT 'itick',
                    cached_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    expires_at DATETIME,
                    UNIQUE(ticker, date, api_source)
                )
            """)
            
            # APIç¼“å­˜è¡¨ - è´¢åŠ¡æŒ‡æ ‡
            conn.execute("""
                CREATE TABLE IF NOT EXISTS financial_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    report_period DATE,
                    period TEXT,  -- ttm, annual, quarterly
                    currency TEXT,
                    market_cap REAL,
                    pe_ratio REAL,
                    pb_ratio REAL,
                    ps_ratio REAL,
                    ev_ebitda REAL,
                    peg_ratio REAL,
                    roe REAL,
                    roa REAL,
                    debt_to_equity REAL,
                    current_ratio REAL,
                    quick_ratio REAL,
                    gross_margin REAL,
                    operating_margin REAL,
                    net_margin REAL,
                    api_source TEXT DEFAULT 'itick',
                    cached_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    expires_at DATETIME,
                    raw_data TEXT,  -- JSONæ ¼å¼å­˜å‚¨åŸå§‹æ•°æ®
                    UNIQUE(ticker, report_period, period, api_source)
                )
            """)
            
            # å†å²è®°å½•è¡¨ - å­˜å‚¨å®Œæ•´çš„æŸ¥è¯¢å’Œåˆ†æç»“æœ
            conn.execute("""
                CREATE TABLE IF NOT EXISTS analysis_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    asset TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    start_date DATE,
                    end_date DATE,
                    start_time TEXT,
                    end_time TEXT,
                    use_current_time BOOLEAN DEFAULT 0,
                    generate_charts BOOLEAN DEFAULT 0,
                    trading_strategy TEXT,
                    analysis_params TEXT,  -- JSONæ ¼å¼å­˜å‚¨åˆ†æå‚æ•°
                    result_summary TEXT,   -- ç»“æœæ‘˜è¦
                    result_details TEXT,   -- JSONæ ¼å¼å­˜å‚¨è¯¦ç»†ç»“æœ
                    status TEXT DEFAULT 'pending',  -- pending/completed/failed/error
                    error_message TEXT,
                    user_ip TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # åˆ›å»ºç´¢å¼•æé«˜æŸ¥è¯¢æ€§èƒ½
            conn.execute("CREATE INDEX IF NOT EXISTS idx_query_records_timestamp ON query_records(timestamp)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_query_records_tickers ON query_records(tickers)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis_results_ticker ON analysis_results(ticker)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_price_cache_ticker_date ON price_cache(ticker, date)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_financial_cache_ticker ON financial_cache(ticker)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_price_cache_expires ON price_cache(expires_at)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_financial_cache_expires ON financial_cache(expires_at)")
            
            # å†å²è®°å½•è¡¨ç´¢å¼•
            conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis_history_timestamp ON analysis_history(timestamp)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis_history_asset ON analysis_history(asset)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis_history_timeframe ON analysis_history(timeframe)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis_history_status ON analysis_history(status)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis_history_session ON analysis_history(session_id)")
            
            conn.commit()
    
    def save_query_record(
        self, 
        tickers: List[str], 
        start_date: str, 
        end_date: str, 
        analysis_params: Dict[str, Any] = None,
        session_id: str = None,
        user_ip: str = None
    ) -> int:
        """
        ä¿å­˜æŸ¥è¯¢è®°å½•
        
        Args:
            tickers: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            analysis_params: åˆ†æå‚æ•°
            session_id: ä¼šè¯ID
            user_ip: ç”¨æˆ·IP
            
        Returns:
            æŸ¥è¯¢è®°å½•ID
        """
        with self.get_connection() as conn:
            cursor = conn.execute("""
                INSERT INTO query_records 
                (session_id, tickers, start_date, end_date, analysis_params, user_ip)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                session_id,
                json.dumps(tickers),
                start_date,
                end_date,
                json.dumps(analysis_params) if analysis_params else None,
                user_ip
            ))
            return cursor.lastrowid
    
    def save_analysis_result(
        self, 
        query_record_id: int, 
        result: Dict[str, Any]
    ):
        """
        ä¿å­˜æŠ€æœ¯åˆ†æç»“æœ
        
        Args:
            query_record_id: æŸ¥è¯¢è®°å½•ID
            result: åˆ†æç»“æœå­—å…¸
        """
        ticker = result.get('ticker', '')
        current_price = result.get('current_price', 0.0)
        analysis = result.get('analysis', {})
        financial_metrics = result.get('financial_metrics', {})
        data_days = result.get('data_days', 0)
        
        # ä»åˆ†æç»“æœä¸­æå–è¯¦ç»†ä¿¡æ¯
        signal = analysis.get('signal', 'ä¸­æ€§')
        confidence = analysis.get('confidence', 0)
        reason = analysis.get('reason', '')
        
        details = analysis.get('details', {})
        macd_signal = details.get('macd', {}).get('signal', 'ä¸­æ€§')
        rsi_signal = details.get('rsi', {}).get('signal', 'ä¸­æ€§') 
        bollinger_signal = details.get('bollinger', {}).get('signal', 'ä¸­æ€§')
        volume_signal = details.get('volume', {}).get('signal', 'ä¸­æ€§')
        
        # ç”Ÿæˆäº¤æ˜“å»ºè®®
        recommendation_data = generate_trading_recommendation(result)
        recommendation = recommendation_data.get('recommendation', '')
        recommendation_action = recommendation_data.get('action', '')
        
        pe_ratio = financial_metrics.get('pe_ratio')
        pb_ratio = financial_metrics.get('pb_ratio')
        
        with self.get_connection() as conn:
            conn.execute("""
                INSERT INTO analysis_results 
                (query_record_id, ticker, current_price, signal, confidence, reason,
                 macd_signal, rsi_signal, bollinger_signal, volume_signal,
                 recommendation, recommendation_action, data_days, pe_ratio, pb_ratio)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                query_record_id, ticker, current_price, signal, confidence, reason,
                macd_signal, rsi_signal, bollinger_signal, volume_signal,
                recommendation, recommendation_action, data_days, pe_ratio, pb_ratio
            ))
    
    def save_analysis_history(
        self,
        asset: str,
        timeframe: str,
        start_date: str,
        end_date: str,
        start_time: str = None,
        end_time: str = None,
        use_current_time: bool = False,
        generate_charts: bool = False,
        trading_strategy: str = None,
        analysis_params: Dict[str, Any] = None,
        result_summary: str = None,
        result_details: Dict[str, Any] = None,
        status: str = 'pending',
        error_message: str = None,
        session_id: str = None,
        user_ip: str = None
    ) -> int:
        """
        ä¿å­˜åˆ†æå†å²è®°å½•
        
        Args:
            asset: èµ„äº§åç§°
            timeframe: æ—¶é—´å‘¨æœŸ
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            use_current_time: æ˜¯å¦ä½¿ç”¨å½“å‰æ—¶é—´
            generate_charts: æ˜¯å¦ç”Ÿæˆå›¾è¡¨
            trading_strategy: äº¤æ˜“ç­–ç•¥
            analysis_params: åˆ†æå‚æ•°
            result_summary: ç»“æœæ‘˜è¦
            result_details: è¯¦ç»†ç»“æœ
            status: çŠ¶æ€
            error_message: é”™è¯¯ä¿¡æ¯
            session_id: ä¼šè¯ID
            user_ip: ç”¨æˆ·IP
            
        Returns:
            å†å²è®°å½•ID
        """
        with self.get_connection() as conn:
            cursor = conn.execute("""
                INSERT INTO analysis_history 
                (session_id, asset, timeframe, start_date, end_date, start_time, end_time,
                 use_current_time, generate_charts, trading_strategy, analysis_params,
                 result_summary, result_details, status, error_message, user_ip)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                session_id,
                asset,
                timeframe,
                start_date,
                end_date,
                start_time,
                end_time,
                use_current_time,
                generate_charts,
                trading_strategy,
                json.dumps(analysis_params) if analysis_params else None,
                result_summary,
                json.dumps(result_details) if result_details else None,
                status,
                error_message,
                user_ip
            ))
            history_id = cursor.lastrowid
            
            # æ‰“å°è¯¦ç»†çš„å­˜å‚¨æ—¥å¿—
            print(f"ğŸ“ å†å²è®°å½•å­˜å‚¨æˆåŠŸ - ID: {history_id}")
            print(f"   ğŸ“Š èµ„äº§: {asset}, æ—¶é—´å‘¨æœŸ: {timeframe}")
            print(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
            print(f"   â° æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
            print(f"   ğŸ”§ äº¤æ˜“ç­–ç•¥: {trading_strategy}")
            print(f"   ğŸ“ˆ çŠ¶æ€: {status}")
            print(f"   ğŸ‘¤ ä¼šè¯ID: {session_id}")
            print(f"   ğŸŒ ç”¨æˆ·IP: {user_ip}")
            if result_summary:
                print(f"   ğŸ“‹ ç»“æœæ‘˜è¦: {result_summary[:100]}...")
            if result_details:
                print(f"   ğŸ“Š è¯¦ç»†ç»“æœ: å·²ä¿å­˜ {len(str(result_details))} å­—ç¬¦")
            
            return history_id
    
    def update_analysis_history(
        self,
        history_id: int,
        result_summary: str = None,
        result_details: Dict[str, Any] = None,
        status: str = None,
        error_message: str = None
    ) -> bool:
        """
        æ›´æ–°åˆ†æå†å²è®°å½•
        
        Args:
            history_id: å†å²è®°å½•ID
            result_summary: ç»“æœæ‘˜è¦
            result_details: è¯¦ç»†ç»“æœ
            status: çŠ¶æ€
            error_message: é”™è¯¯ä¿¡æ¯
            
        Returns:
            æ˜¯å¦æˆåŠŸæ›´æ–°
        """
        try:
            with self.get_connection() as conn:
                # æ„å»ºæ›´æ–°è¯­å¥
                update_fields = []
                update_values = []
                
                if result_summary is not None:
                    update_fields.append("result_summary = ?")
                    update_values.append(result_summary)
                
                if result_details is not None:
                    update_fields.append("result_details = ?")
                    update_values.append(json.dumps(result_details))
                
                if status is not None:
                    update_fields.append("status = ?")
                    update_values.append(status)
                
                if error_message is not None:
                    update_fields.append("error_message = ?")
                    update_values.append(error_message)
                
                # æ·»åŠ æ›´æ–°æ—¶é—´
                update_fields.append("updated_at = CURRENT_TIMESTAMP")
                
                if update_fields:
                    update_values.append(history_id)
                    sql = f"UPDATE analysis_history SET {', '.join(update_fields)} WHERE id = ?"
                    conn.execute(sql, update_values)
                    conn.commit()
                    
                    # æ‰“å°è¯¦ç»†çš„æ›´æ–°æ—¥å¿—
                    print(f"ğŸ”„ å†å²è®°å½•æ›´æ–°æˆåŠŸ - ID: {history_id}")
                    if status:
                        print(f"   ğŸ“ˆ çŠ¶æ€æ›´æ–°ä¸º: {status}")
                    if result_summary:
                        print(f"   ğŸ“‹ ç»“æœæ‘˜è¦æ›´æ–°: {result_summary[:100]}...")
                    if result_details:
                        print(f"   ğŸ“Š è¯¦ç»†ç»“æœæ›´æ–°: å·²ä¿å­˜ {len(str(result_details))} å­—ç¬¦")
                    if error_message:
                        print(f"   âŒ é”™è¯¯ä¿¡æ¯: {error_message}")
                    
                    return True
                else:
                    return False
        except Exception as e:
            print(f"âŒ æ›´æ–°åˆ†æå†å²è®°å½•å¤±è´¥: {e}")
            return False
    
    def get_analysis_history_list(
        self,
        limit: int = 50,
        asset: str = None,
        timeframe: str = None,
        status: str = None,
        days_back: int = 30
    ) -> List[Dict[str, Any]]:
        """
        è·å–åˆ†æå†å²è®°å½•åˆ—è¡¨
        
        Args:
            limit: è¿”å›è®°å½•æ•°é™åˆ¶
            asset: è¿‡æ»¤ç‰¹å®šèµ„äº§
            timeframe: è¿‡æ»¤ç‰¹å®šæ—¶é—´å‘¨æœŸ
            status: è¿‡æ»¤ç‰¹å®šçŠ¶æ€
            days_back: è¿”å›å¤šå°‘å¤©å†…çš„è®°å½•
            
        Returns:
            å†å²è®°å½•åˆ—è¡¨
        """
        with self.get_connection() as conn:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶ - ç§»é™¤session_idè¿‡æ»¤ï¼Œå…è®¸è·¨sessionæŸ¥çœ‹æ‰€æœ‰è®°å½•
            conditions = ["created_at >= datetime('now', '-' || ? || ' days')"]
            params = [days_back]
            
            if asset:
                conditions.append("asset = ?")
                params.append(asset)
            
            if timeframe:
                conditions.append("timeframe = ?")
                params.append(timeframe)
            
            if status:
                conditions.append("status = ?")
                params.append(status)
            
            # ç§»é™¤session_idè¿‡æ»¤æ¡ä»¶
            where_clause = " AND ".join(conditions)
            
            cursor = conn.execute(f"""
                SELECT * FROM analysis_history 
                WHERE {where_clause}
                ORDER BY created_at DESC
                LIMIT ?
            """, params + [limit])
            
            rows = cursor.fetchall()
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨å¹¶å¤„ç†JSONå­—æ®µ
            history_list = []
            for row in rows:
                record = dict(row)
                # è§£æJSONå­—æ®µ
                if record.get('analysis_params'):
                    record['analysis_params'] = json.loads(record['analysis_params'])
                if record.get('result_details'):
                    record['result_details'] = json.loads(record['result_details'])
                history_list.append(record)
            
            # æ‰“å°è¯¦ç»†çš„è¯»å–æ—¥å¿—
            print(f"ğŸ“– å†å²è®°å½•è¯»å–æˆåŠŸ")
            print(f"   ğŸ” æŸ¥è¯¢æ¡ä»¶: èµ„äº§={asset}, æ—¶é—´å‘¨æœŸ={timeframe}, çŠ¶æ€={status}")
            print(f"   ğŸ“Š è¿”å›è®°å½•æ•°: {len(history_list)} æ¡")
            print(f"   â° æ—¶é—´èŒƒå›´: æœ€è¿‘ {days_back} å¤©")
            if history_list:
                print(f"   ğŸ“… æœ€æ—©è®°å½•: {history_list[-1].get('created_at')}")
                print(f"   ğŸ“… æœ€æ–°è®°å½•: {history_list[0].get('created_at')}")
                status_counts = {}
                for record in history_list:
                    status = record.get('status', 'unknown')
                    status_counts[status] = status_counts.get(status, 0) + 1
                print(f"   ğŸ“ˆ çŠ¶æ€åˆ†å¸ƒ: {status_counts}")
            
            return history_list
    
    def get_analysis_history_by_id(self, history_id: int) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®IDè·å–åˆ†æå†å²è®°å½•
        
        Args:
            history_id: å†å²è®°å½•ID
            
        Returns:
            å†å²è®°å½•è¯¦æƒ…ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        with self.get_connection() as conn:
            cursor = conn.execute("""
                SELECT * FROM analysis_history WHERE id = ?
            """, (history_id,))
            
            row = cursor.fetchone()
            if row:
                record = dict(row)
                # è§£æJSONå­—æ®µ
                if record.get('analysis_params'):
                    record['analysis_params'] = json.loads(record['analysis_params'])
                if record.get('result_details'):
                    record['result_details'] = json.loads(record['result_details'])
                return record
            return None
    
    def delete_analysis_history(self, history_id: int) -> bool:
        """
        åˆ é™¤åˆ†æå†å²è®°å½•
        
        Args:
            history_id: å†å²è®°å½•ID
            
        Returns:
            æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("DELETE FROM analysis_history WHERE id = ?", (history_id,))
                conn.commit()
                return cursor.rowcount > 0
        except Exception as e:
            print(f"åˆ é™¤åˆ†æå†å²è®°å½•å¤±è´¥: {e}")
            return False
    
    def clear_analysis_history(self, days_older_than: int = None) -> int:
        """
        æ¸…ç†åˆ†æå†å²è®°å½•
        
        Args:
            days_older_than: åˆ é™¤å¤šå°‘å¤©å‰çš„è®°å½•ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ é™¤æ‰€æœ‰è®°å½•
            
        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        try:
            with self.get_connection() as conn:
                if days_older_than:
                    cursor = conn.execute("""
                        DELETE FROM analysis_history 
                        WHERE created_at < datetime('now', '-' || ? || ' days')
                    """, (days_older_than,))
                else:
                    cursor = conn.execute("DELETE FROM analysis_history")
                
                conn.commit()
                return cursor.rowcount
        except Exception as e:
            print(f"æ¸…ç†åˆ†æå†å²è®°å½•å¤±è´¥: {e}")
            return 0
    
    def cache_price_data(
        self, 
        ticker: str, 
        price_data: List[Dict[str, Any]], 
        cache_hours: int = 24
    ):
        """
        ç¼“å­˜ä»·æ ¼æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            price_data: ä»·æ ¼æ•°æ®åˆ—è¡¨
            cache_hours: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰
        """
        expires_at = datetime.now() + timedelta(hours=cache_hours)
        
        with self.get_connection() as conn:
            for price in price_data:
                # ä½¿ç”¨ INSERT OR REPLACE å¤„ç†é‡å¤æ•°æ®
                conn.execute("""
                    INSERT OR REPLACE INTO price_cache 
                    (ticker, date, open_price, high_price, low_price, close_price, 
                     volume, expires_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    ticker.upper(),
                    price.get('time', price.get('date')),
                    price.get('open'),
                    price.get('high'),
                    price.get('low'),
                    price.get('close'),
                    price.get('volume'),
                    expires_at
                ))
    
    def get_cached_price_data(
        self, 
        ticker: str, 
        start_date: str, 
        end_date: str
    ) -> List[Dict[str, Any]]:
        """
        ä»ç¼“å­˜ä¸­è·å–ä»·æ ¼æ•°æ®
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            ä»·æ ¼æ•°æ®åˆ—è¡¨ï¼Œå¦‚æœç¼“å­˜è¿‡æœŸæˆ–ä¸å­˜åœ¨è¿”å›ç©ºåˆ—è¡¨
        """
        with self.get_connection() as conn:
            cursor = conn.execute("""
                SELECT date, open_price, high_price, low_price, close_price, volume
                FROM price_cache 
                WHERE ticker = ? AND date >= ? AND date <= ? 
                AND expires_at > CURRENT_TIMESTAMP
                ORDER BY date
            """, (ticker.upper(), start_date, end_date))
            
            rows = cursor.fetchall()
            
            return [
                {
                    'time': row['date'],
                    'open': row['open_price'],
                    'high': row['high_price'],
                    'low': row['low_price'],
                    'close': row['close_price'],
                    'volume': row['volume']
                }
                for row in rows
            ]
    
    def get_cached_dates(self, ticker: str) -> List[str]:
        """
        è·å–ç‰¹å®šè‚¡ç¥¨å·²ç¼“å­˜çš„æ‰€æœ‰æ—¥æœŸ
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            
        Returns:
            å·²ç¼“å­˜æ—¥æœŸåˆ—è¡¨
        """
        with self.get_connection() as conn:
            cursor = conn.execute("""
                SELECT DISTINCT date
                FROM price_cache 
                WHERE ticker = ? AND expires_at > CURRENT_TIMESTAMP
                ORDER BY date
            """, (ticker.upper(),))
            
            rows = cursor.fetchall()
            return [row['date'] for row in rows]
    
    def cache_financial_data(
        self, 
        ticker: str, 
        financial_data: List[Dict[str, Any]], 
        cache_hours: int = 24 * 7  # è´¢åŠ¡æ•°æ®ç¼“å­˜1å‘¨
    ):
        """
        ç¼“å­˜è´¢åŠ¡æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            financial_data: è´¢åŠ¡æ•°æ®åˆ—è¡¨
            cache_hours: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰
        """
        expires_at = datetime.now() + timedelta(hours=cache_hours)
        
        with self.get_connection() as conn:
            for data in financial_data:
                conn.execute("""
                    INSERT OR REPLACE INTO financial_cache 
                    (ticker, report_period, period, currency, market_cap, pe_ratio, 
                     pb_ratio, ps_ratio, ev_ebitda, peg_ratio, roe, roa, 
                     debt_to_equity, current_ratio, quick_ratio, gross_margin, 
                     operating_margin, net_margin, expires_at, raw_data)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    ticker.upper(),
                    data.get('report_period'),
                    data.get('period', 'ttm'),
                    data.get('currency', 'USD'),
                    data.get('market_cap'),
                    data.get('price_to_earnings_ratio'),
                    data.get('price_to_book_ratio'),
                    data.get('price_to_sales_ratio'),
                    data.get('enterprise_value_to_ebitda_ratio'),
                    data.get('peg_ratio'),
                    data.get('return_on_equity'),
                    data.get('return_on_assets'),
                    data.get('debt_to_equity_ratio'),
                    data.get('current_ratio'),
                    data.get('quick_ratio'),
                    data.get('gross_margin'),
                    data.get('operating_margin'),
                    data.get('net_margin'),
                    expires_at,
                    json.dumps(data)
                ))
    
    def get_cached_financial_data(
        self, 
        ticker: str, 
        end_date: str = None
    ) -> List[Dict[str, Any]]:
        """
        ä»ç¼“å­˜ä¸­è·å–è´¢åŠ¡æ•°æ®
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            è´¢åŠ¡æ•°æ®åˆ—è¡¨
        """
        with self.get_connection() as conn:
            if end_date:
                cursor = conn.execute("""
                    SELECT raw_data
                    FROM financial_cache 
                    WHERE ticker = ? AND report_period <= ? 
                    AND expires_at > CURRENT_TIMESTAMP
                    ORDER BY report_period DESC
                """, (ticker.upper(), end_date))
            else:
                cursor = conn.execute("""
                    SELECT raw_data
                    FROM financial_cache 
                    WHERE ticker = ? AND expires_at > CURRENT_TIMESTAMP
                    ORDER BY report_period DESC
                """, (ticker.upper(),))
            
            rows = cursor.fetchall()
            
            return [json.loads(row['raw_data']) for row in rows]
    
    def get_query_history(
        self, 
        limit: int = 50, 
        ticker: str = None
    ) -> pd.DataFrame:
        """
        è·å–æŸ¥è¯¢å†å²è®°å½•
        
        Args:
            limit: è¿”å›è®°å½•æ•°é™åˆ¶
            ticker: è¿‡æ»¤ç‰¹å®šè‚¡ç¥¨ä»£ç 
            
        Returns:
            æŸ¥è¯¢å†å²DataFrame
        """
        with self.get_connection() as conn:
            if ticker:
                sql = """
                    SELECT qr.*, 
                           COUNT(ar.id) as result_count,
                           GROUP_CONCAT(ar.ticker) as analyzed_tickers,
                           AVG(ar.confidence) as avg_confidence
                    FROM query_records qr
                    LEFT JOIN analysis_results ar ON qr.id = ar.query_record_id
                    WHERE qr.tickers LIKE ?
                    GROUP BY qr.id
                    ORDER BY qr.timestamp DESC
                    LIMIT ?
                """
                df = pd.read_sql_query(sql, conn, params=[f'%{ticker.upper()}%', limit])
            else:
                sql = """
                    SELECT qr.*, 
                           COUNT(ar.id) as result_count,
                           GROUP_CONCAT(ar.ticker) as analyzed_tickers,
                           AVG(ar.confidence) as avg_confidence
                    FROM query_records qr
                    LEFT JOIN analysis_results ar ON qr.id = ar.query_record_id
                    GROUP BY qr.id
                    ORDER BY qr.timestamp DESC
                    LIMIT ?
                """
                df = pd.read_sql_query(sql, conn, params=[limit])
        
        # å¤„ç†JSONå­—æ®µ
        if not df.empty:
            df['tickers'] = df['tickers'].apply(lambda x: json.loads(x) if x else [])
            df['analysis_params'] = df['analysis_params'].apply(lambda x: json.loads(x) if x else {})
        
        return df
    
    def get_analysis_history(
        self, 
        ticker: str = None, 
        limit: int = 100
    ) -> pd.DataFrame:
        """
        è·å–æŠ€æœ¯åˆ†æå†å²è®°å½•
        
        Args:
            ticker: è¿‡æ»¤ç‰¹å®šè‚¡ç¥¨ä»£ç 
            limit: è¿”å›è®°å½•æ•°é™åˆ¶
            
        Returns:
            åˆ†æå†å²DataFrame
        """
        with self.get_connection() as conn:
            if ticker:
                sql = """
                    SELECT ar.*, qr.timestamp as query_time, qr.start_date, qr.end_date
                    FROM analysis_results ar
                    JOIN query_records qr ON ar.query_record_id = qr.id
                    WHERE ar.ticker = ?
                    ORDER BY ar.created_at DESC
                    LIMIT ?
                """
                df = pd.read_sql_query(sql, conn, params=[ticker.upper(), limit])
            else:
                sql = """
                    SELECT ar.*, qr.timestamp as query_time, qr.start_date, qr.end_date
                    FROM analysis_results ar
                    JOIN query_records qr ON ar.query_record_id = qr.id
                    ORDER BY ar.created_at DESC
                    LIMIT ?
                """
                df = pd.read_sql_query(sql, conn, params=[limit])
        
        return df
    
    def cleanup_expired_cache(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ•°æ®"""
        with self.get_connection() as conn:
            # æ¸…ç†è¿‡æœŸçš„ä»·æ ¼ç¼“å­˜
            cursor = conn.execute("""
                DELETE FROM price_cache 
                WHERE expires_at <= CURRENT_TIMESTAMP
            """)
            price_deleted = cursor.rowcount
            
            # æ¸…ç†è¿‡æœŸçš„è´¢åŠ¡æ•°æ®ç¼“å­˜
            cursor = conn.execute("""
                DELETE FROM financial_cache 
                WHERE expires_at <= CURRENT_TIMESTAMP
            """)
            financial_deleted = cursor.rowcount
            
            conn.commit()
            
            if price_deleted > 0 or financial_deleted > 0:
                print(f"ğŸ§¹ æ¸…ç†è¿‡æœŸç¼“å­˜: ä»·æ ¼æ•°æ® {price_deleted} æ¡, è´¢åŠ¡æ•°æ® {financial_deleted} æ¡")
    
    def clear_ticker_cache(self, ticker: str):
        """æ¸…é™¤ç‰¹å®šè‚¡ç¥¨çš„æ‰€æœ‰ç¼“å­˜æ•°æ®"""
        with self.get_connection() as conn:
            # æ¸…é™¤ä»·æ ¼ç¼“å­˜
            cursor = conn.execute("""
                DELETE FROM price_cache 
                WHERE ticker = ?
            """, (ticker.upper(),))
            price_deleted = cursor.rowcount
            
            # æ¸…é™¤è´¢åŠ¡æ•°æ®ç¼“å­˜
            cursor = conn.execute("""
                DELETE FROM financial_cache 
                WHERE ticker = ?
            """, (ticker.upper(),))
            financial_deleted = cursor.rowcount
            
            conn.commit()
            
            if price_deleted > 0 or financial_deleted > 0:
                print(f"ğŸ§¹ æ¸…é™¤ {ticker} ç¼“å­˜: ä»·æ ¼æ•°æ® {price_deleted} æ¡, è´¢åŠ¡æ•°æ® {financial_deleted} æ¡")
            
            return price_deleted + financial_deleted
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self.get_connection() as conn:
            # ä»·æ ¼ç¼“å­˜ç»Ÿè®¡
            cursor = conn.execute("""
                SELECT 
                    COUNT(*) as total_records,
                    COUNT(DISTINCT ticker) as unique_tickers,
                    MIN(date) as earliest_date,
                    MAX(date) as latest_date,
                    COUNT(CASE WHEN expires_at > CURRENT_TIMESTAMP THEN 1 END) as valid_records
                FROM price_cache
            """)
            price_stats = dict(cursor.fetchone())
            
            # è´¢åŠ¡ç¼“å­˜ç»Ÿè®¡
            cursor = conn.execute("""
                SELECT 
                    COUNT(*) as total_records,
                    COUNT(DISTINCT ticker) as unique_tickers,
                    COUNT(CASE WHEN expires_at > CURRENT_TIMESTAMP THEN 1 END) as valid_records
                FROM financial_cache
            """)
            financial_stats = dict(cursor.fetchone())
            
            # æŸ¥è¯¢è®°å½•ç»Ÿè®¡
            cursor = conn.execute("""
                SELECT 
                    COUNT(*) as total_queries,
                    COUNT(DISTINCT DATE(timestamp)) as query_days,
                    MIN(timestamp) as first_query,
                    MAX(timestamp) as last_query
                FROM query_records
            """)
            query_stats = dict(cursor.fetchone())
            
            return {
                'price_cache': price_stats,
                'financial_cache': financial_stats,
                'query_records': query_stats
            }

    def check_existing_analysis(
        self,
        asset: str,
        timeframe: str,
        start_date: str,
        end_date: str,
        start_time: str = None,
        end_time: str = None,
        trading_strategy: str = None,
        session_id: str = None,
        max_hours_old: int = 24
    ) -> Optional[Dict[str, Any]]:
        """
        æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒæŸ¥è¯¢æ¡ä»¶çš„åˆ†æç»“æœ
        
        Args:
            asset: èµ„äº§åç§°
            timeframe: æ—¶é—´å‘¨æœŸ
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            trading_strategy: äº¤æ˜“ç­–ç•¥
            max_hours_old: æœ€å¤§å…è®¸çš„å°æ—¶æ•°ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
            
        Returns:
            å¦‚æœå­˜åœ¨ç¬¦åˆæ¡ä»¶çš„è®°å½•ï¼Œè¿”å›è®°å½•è¯¦æƒ…ï¼Œå¦åˆ™è¿”å›None
        """
        with self.get_connection() as conn:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶ - ç§»é™¤session_idè¿‡æ»¤ï¼Œä½¿ç”¨è‚¡ç¥¨ID+å‘¨æœŸ+æ—¥æœŸ+ç­–ç•¥ä½œä¸ºkey
            conditions = [
                "asset = ?",
                "timeframe = ?",
                "start_date = ?",
                "end_date = ?",
                "status = 'completed'",
                "created_at >= datetime('now', '-24 hours')"  # ç›´æ¥ä½¿ç”¨å›ºå®š24å°æ—¶
            ]
            params = [asset, timeframe, start_date, end_date]
            
            # ç§»é™¤start_timeå’Œend_timeçš„è¿‡æ»¤æ¡ä»¶ï¼Œå› ä¸ºå®ƒä»¬ä¸æ˜¯å¿…éœ€çš„æŸ¥è¯¢key
            # åªä½¿ç”¨asset, timeframe, start_date, end_date, trading_strategyä½œä¸ºæŸ¥è¯¢key
                
            if trading_strategy:
                conditions.append("trading_strategy = ?")
                params.append(trading_strategy)
            else:
                conditions.append("trading_strategy IS NULL")
            
            # ç§»é™¤session_idè¿‡æ»¤æ¡ä»¶ï¼Œå…è®¸è·¨sessionå…±äº«ç¼“å­˜
            where_clause = " AND ".join(conditions)
            
            # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ” æ‰§è¡Œçš„SQLæŸ¥è¯¢:")
            print(f"   WHEREæ¡ä»¶: {where_clause}")
            print(f"   å‚æ•°åˆ—è¡¨: {params}")
            
            cursor = conn.execute(f"""
                SELECT * FROM analysis_history 
                WHERE {where_clause}
                ORDER BY created_at DESC
                LIMIT 1
            """, params)
            
            row = cursor.fetchone()
            if row:
                record = dict(row)
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                print(f"ğŸ” æ‰¾åˆ°æ•°æ®åº“è®°å½• - ID: {record['id']}")
                print(f"   ğŸ“Š æŸ¥è¯¢æ¡ä»¶åŒ¹é…æˆåŠŸ")
                
                # è§£æJSONå­—æ®µ
                try:
                    if record.get('analysis_params'):
                        record['analysis_params'] = json.loads(record['analysis_params'])
                    if record.get('result_details'):
                        record['result_details'] = json.loads(record['result_details'])
                    
                    print(f"âœ… æ‰¾åˆ°ç¼“å­˜çš„åˆ†æç»“æœ - ID: {record['id']}")
                    print(f"   ğŸ“Š èµ„äº§: {asset}, æ—¶é—´å‘¨æœŸ: {timeframe}")
                    print(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
                    print(f"   â° æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
                    print(f"   ğŸ”§ äº¤æ˜“ç­–ç•¥: {trading_strategy}")
                    print(f"   ğŸ“ˆ åˆ›å»ºæ—¶é—´: {record['created_at']}")
                    
                    return record
                except Exception as e:
                    print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
                    # å³ä½¿JSONè§£æå¤±è´¥ï¼Œä¹Ÿè¿”å›è®°å½•
                    return record
            
            print(f"âŒ æœªæ‰¾åˆ°ç¼“å­˜çš„åˆ†æç»“æœ")
            print(f"   ğŸ“Š èµ„äº§: {asset}, æ—¶é—´å‘¨æœŸ: {timeframe}")
            print(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
            print(f"   â° æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
            print(f"   ğŸ”§ äº¤æ˜“ç­–ç•¥: {trading_strategy}")
            
            return None


# å…¨å±€æ•°æ®åº“å®ä¾‹
_db_manager = None


def get_database_manager() -> DatabaseManager:
    """è·å–å…¨å±€æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹"""
    global _db_manager
    if _db_manager is None:
        _db_manager = DatabaseManager()
    return _db_manager


def generate_trading_recommendation(analysis_result):
    """
    ç”Ÿæˆäº¤æ˜“å»ºè®®ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰
    """
    if not analysis_result:
        return {"recommendation": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå»ºè®®", "action": "æ— æ“ä½œ", "reason": "", "confidence": 0}
    
    signal = analysis_result['analysis']['signal']
    confidence = analysis_result['analysis']['confidence']
    reason = analysis_result['analysis']['reason']
    
    # ç”Ÿæˆå»ºè®®
    if signal == 'çœ‹æ¶¨' and confidence >= 60:
        recommendation = f"ğŸŸ¢ ä¹°å…¥å»ºè®®"
        action = "è€ƒè™‘ä¹°å…¥"
    elif signal == 'çœ‹è·Œ' and confidence >= 60:
        recommendation = f"ğŸ”´ å–å‡ºå»ºè®®"
        action = "è€ƒè™‘å–å‡º"
    else:
        recommendation = f"ğŸŸ¡ æŒæœ‰å»ºè®®"
        action = "ç»§ç»­è§‚å¯Ÿ"
    
    return {
        'recommendation': recommendation,
        'action': action,
        'reason': reason,
        'confidence': confidence
    }